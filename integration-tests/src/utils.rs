use std::sync::Arc;

use arrow::{
    array::{ArrayRef, RecordBatch, RecordBatchOptions},
    util::pretty::pretty_format_batches_with_schema,
};
use datafusion::{
    physical_plan::{collect, display::DisplayableExecutionPlan},
    prelude::SessionContext,
};
use futures::TryStreamExt;
use indexlake::{
    ILError, ILResult,
    catalog::INTERNAL_ROW_ID_FIELD_NAME,
    table::{Table, TableScan, TableSearch},
    utils::project_schema,
};

pub fn sort_record_batches(batches: &[RecordBatch], sort_col: &str) -> ILResult<RecordBatch> {
    if batches.is_empty() {
        return Err(ILError::invalid_input("record batches is empty"));
    }
    let record = arrow::compute::concat_batches(&batches[0].schema(), batches)?;

    let sort_col_idx = record.schema().index_of(sort_col)?;
    let sort_array = record.column(sort_col_idx);

    let indices = arrow::compute::sort_to_indices(sort_array, None, None)?;

    let sorted_arrays: Vec<ArrayRef> = record
        .columns()
        .iter()
        .map(|col| arrow::compute::take(col, &indices, None))
        .collect::<arrow::error::Result<_>>()?;

    let options = RecordBatchOptions::new().with_row_count(Some(record.num_rows()));
    Ok(RecordBatch::try_new_with_options(
        record.schema(),
        sorted_arrays,
        &options,
    )?)
}

pub async fn full_table_scan(table: &Table) -> ILResult<String> {
    table_scan(table, TableScan::default()).await
}

pub async fn table_scan(table: &Table, scan: TableScan) -> ILResult<String> {
    let batch_schema = Arc::new(project_schema(&table.schema, scan.projection.as_ref())?);
    let stream = table.scan(scan).await?;
    let batches = stream.try_collect::<Vec<_>>().await?;
    let sorted_batches = if batches.is_empty() {
        vec![]
    } else {
        vec![sort_record_batches(&batches, INTERNAL_ROW_ID_FIELD_NAME)?]
    };
    let table_str = pretty_format_batches_with_schema(batch_schema, &sorted_batches)?.to_string();
    Ok(table_str)
}

pub async fn table_search(table: &Table, search: TableSearch) -> ILResult<String> {
    let batch_schema = Arc::new(project_schema(&table.schema, search.projection.as_ref())?);
    let stream = table.search(search).await?;
    let batches = stream.try_collect::<Vec<_>>().await?;
    let table_str = pretty_format_batches_with_schema(batch_schema, &batches)?.to_string();
    Ok(table_str)
}

pub async fn datafusion_insert(ctx: &SessionContext, sql: &str) -> String {
    datafusion_exec_and_sort(ctx, sql, None).await
}

pub async fn datafusion_scan(ctx: &SessionContext, sql: &str) -> String {
    datafusion_exec_and_sort(ctx, sql, Some(INTERNAL_ROW_ID_FIELD_NAME)).await
}

pub async fn datafusion_exec_and_sort(
    ctx: &SessionContext,
    sql: &str,
    sort_col: Option<&str>,
) -> String {
    let df = ctx.sql(sql).await.unwrap();
    let plan = df.create_physical_plan().await.unwrap();
    println!(
        "plan: {}",
        DisplayableExecutionPlan::new(plan.as_ref()).indent(true)
    );
    let plan_schema = plan.schema();
    let batches = collect(plan, ctx.task_ctx()).await.unwrap();
    let sorted_batches = if batches.is_empty() {
        vec![]
    } else if let Some(sort_col) = sort_col {
        vec![sort_record_batches(&batches, sort_col).unwrap()]
    } else {
        batches
    };
    let result_str = pretty_format_batches_with_schema(plan_schema, &sorted_batches)
        .unwrap()
        .to_string();
    println!("{}", result_str);
    result_str
}
